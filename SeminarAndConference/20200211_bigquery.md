# Google BigQuery

> 2020.02.11 Google Customer Engineer, 이 정운

## 왜 BigQuery?

* 2018년 이미 엑사바이트 이상의 데이터들이 저장되어있다.
* 많은 회사들이 쓰고있다.

## 특징

* 완전 관리 및 서버리스
* 기존 데이터 웨어하우스에서는 전체 시간중 15% 정도 밖에 분석과 통계에 사용할 수 없다.
* 내 시간을 빅 쿼리에서는 100%를 분석에 투입할 수 있다.
* 빠르다. 4TB 이상의 데이터 처리에 20초 정도.
* 왜 빠르냐?
    * 동적 할당이 가능하다.
    * CPU 존과 스토리지 존이 분리되어 있고, 그 사이를 주피터라는 매우 빠른 네트웍이 연결되어 있다.
    * 원하는 만큼 CPU를 땡겨다가 연산의 속도를 높일 수 있다. 단, 돈은 내야지 ㅋ
    * 실제 쿼리를 날리지 않으면 비용 발생하지 않는다.
* 사례
    * 내드테크 기업 와이더플래닛
        * DBA 없이 손쉬운 운영 관리가 가능
        * 스토리지 증설 고민에서 해방
* 비용은?
    * 1TB에 월 20$
    * 장기저장 1TB에 월 10$
        * 90일 지나면 select 해도 장기 저장 discount 된다.
    * 쿼리 1TB에 5$
    * 빅쿼리 캐시된 테이블 활용하면 매우 빠르다. 1회만 비용을 받는다. 쿼리 전체가 캐시키.
        * 다만 같은 account, 또는 vm 을 활용해서.
    * **CPU 비용을 받지 않는다!** 데이터 스캔량에 대해서 비용이지, CPU는 마음대로 써도 된다!!
    * 그래도 비용이 걱정되면
        * custom quotas
        * Flat rate(정액제)
* best practice
    * 테이블 샤딩
        * 빅쿼리 데이터 셋에 테이블 뒤에 날짜를 저장하면 빅쿼리에서 알아서 샤딩한다. 
        * (* - 아스테리카) 사용으로 년도별, 월별 처리도 가능
    * 파티셔닝
        * 타임스탬프, 데이트 기준 + 베타버전(Integer range 기준)
    * 클러스터링
* 로그를 쌓는 것 만이 아니라 분석도 중요하다.
    * 분석을 위해서 RDB 대신 컬럼화 된 DB가 사용된다.
    * 고객입장에서 보면 비용이 다르다. 데이터 스캔량 자체가 다르다. 컬럼으로 쪼개놔서 스캔량이 적다.
* 빅쿼리 GIS
    * 쏘카, 타다에서 거리 계산시 사용해서 요금 계산.
* Datasets
    * 각 서비스 별로 프로젝트를 나눠서 그 안에 데이터 셋을 구성할 수 있다.
* 빅쿼리의 가장 큰 장점은 공유가 가능하다는 것이다.
    * 스토리지와 CPU가 나뉘어져 있으므로, 스토리지만 공유가 가능하다.
    * 해당 데이터셋을 A팀에서 B팀으로 복제하는 구조가 아니라 팀 추가해서 공유하는 구조다.
* 사례
    * 게임빌/컴투스 hive analyitics
* 데이터 로딩은 어떻게?
    * cli나 웹 ui, 등등 여러 포맷으로 그냥 밀어넣을 수 있음
* 로그는?
    * GCP 스택드라이버 클릭 한번으로 빅쿼리에 밀어 넣을 수 있다.
    * 온프레미스에서는 Blue Medora를 통해서 스택드라이버에 보낸 다음에 빅쿼리로 보내서(어떻게? 클릭한번으로) 분석.
* AWS 데이터 통합 가능
    * NBT 사례
        * AWS RDS에서 스택드라이버에 밀어 넣어서 빅쿼리로 분석.
* 더 많은 데이터...
    * GA, 파이어베이스 애널리틱스, 유튜브 같은 구글 제품등은 빅쿼리로 바로 들어온다.
    * 더 많은 데이터를 얻을 수 있다.
    * 전송 액션을 통해서 타사(AWS S3)에 있는 데이터도 input 가능하다.
* 빅쿼리가 그리고 있는 미래
    * Datalake
        * 모든 데이터가 모이는 데이터 호수
* 데이터를 더 잘보기 위해서
    * 쿼리
    * 데이터 스튜디오
        * 무상제공
    * 스프레드시트
        * 데이터 커넥터를 통해서 빅쿼리에 있는 데이터를 쭉 땡겨와서 시트를 그린다.
        * 더 놀라운건 실시간 연결되어있다. 빅쿼리랑. ㄷ ㄷ ㄷ
        * 빅쿼리 업데이트시 데이터 시트 업데이트 필요 없다.
        * 데이터 스캔량에 대한 비용 과금 된다.
* 구글 클라우드 서밋 서울 - 빅쿼리와 함께 새롭게 정의하는 데이터 웨어하우징(유튜브)

## 구글의 새로운 ML 접근 방법

* 머신러닝
    * 코드를 작성하는 대신 데이터를 알고리즘에 공급하면, 데이터가 룰을 만들어 낸다.
* ML은 파이프라인 필요하다.
* ML은 많은 데이터가 필요하고, 그래야 결과가 잘 나온다. 근데 걔네가 파이프라인을 통해 이동한다.
* 많은 데이터의 이동을 줄일 수 있다면?
* 데이터가 모여있는 Data Lake에서 바로 머신러능을 하면 안될까? - 구글의 생각
* 그래서 나온게 BigQuery ML이다.
* K-means 클러스터링
    * 고객 세분화 알고리즘
* Matrix Factorization
    * 넷플릭스 추천 알고리즘 - 빈칸에 어떤 값이 들어가면 좋을까?
* 텐서플로우 모델 가져오기
* 전처리 함수
* AutoML
    * 머신러닝이 머신러닝을 활용해서 모델을 만들어 낸다.
    * 데이터만 주세요, 그리고 예측하세요. 나머지 부분은 머신러닝이 해줄거에요 - autoML의 사상
    * 데이터는?
    * 빅쿼리에서 가져오면 되지~

## Qwiklabs

* 실습
    * https://taw.qwiklabs.com/
    * 퀵랩 시작
        * id/pw 발급받고
    * 시크릿모드로 콘솔 접속
* 자기주도형 + 퀘스트형 실습 형태가 개인적으로 너무 만족스러웠음.